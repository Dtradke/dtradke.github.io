<!DOCTYPE html>
<html lang="en">
<head>
	<title>ALA 23 Tuning Credo LP</title>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
	<link rel="stylesheet" href="css/animate.css">
	<link rel="stylesheet" href="css/flexslider.css">
	<link rel="stylesheet" href="fonts/icomoon/style.css">

	<link rel="stylesheet" href="css/bootstrap.css">
	<link rel="stylesheet" href="css/style.css">

	<link href="https://fonts.googleapis.com/css?family=Nunito+Sans:200,300,400,700" rel="stylesheet">



	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-T9DXC9V5KJ"></script>
	<script>
  	window.dataLayer = window.dataLayer || [];
  	function gtag(){dataLayer.push(arguments);}
  	gtag('js', new Date());

  	gtag('config', 'G-T9DXC9V5KJ');
	</script>

</head>
<body data-spy="scroll" data-target="#pb-navbar" data-offset="200">



 <section class="site-section" id="section-featpubs">
	 <div class="container">
		 <div class="row">
			 <div class="col-md-12 mb-5">
				 <div class="section-heading text-center">
					 <h1><strong>Learning to Learn Group Alignment: A Self-Tuning Credo Framework with Multiagent Teams</strong></h1>
           <h2>
             <a rel="nofollow" href="https://cs.uwaterloo.ca/~dtradke/">David Radke*</a> and
             <a rel="nofollow" href="https://ktilbury.github.io">Kyle Tilbury*</a>
           </h2>
					 <h3>* denotes equal contribution</h3>
           <h2>Proceedings: <a rel="nofollow" href="https://alaworkshop2023.github.io">Adaptive and Learning Agents Workshop (ALA) at AAMAS 2023</a></h2>
           <br>
           <h3><a rel="nofollow" href="https://arxiv.org/pdf/2304.07337.pdf"><span style="color:DarkKhaki"><b>[Click for Paper]</b></span></a></h3>
					 <!-- <h3><a rel="nofollow" href="pdfs/Radke_AISA21_Camera-Ready_Banner.pdf"><span style="color:DarkKhaki"><b>[Click for Paper]</b></span></a></h3> -->



         </div>
			 </div>
		 </div>

			 <div class="row">
				 <div class="col-md-12">
					 <div class="text-center">

			 <!-- <div class="col-sm-6 col-lg-4 mb-4">
				 <div class="blog-entry"> -->
					 <img src="images/credo_tuning_full.png" alt="Credo Image" height="350">
					 <div class="blog-entry-text">
						 <!-- <h3><a rel="nofollow" href="pdfs/Radke_AISA21_Camera-Ready_wBanner.pdf">Passing and Pressure Metrics in Ice Hockey <br><span style="color:DarkKhaki"><b>[Click for Paper]</b></span></a></h3> -->
             <p class="mb-4"><b><strong><span style="color:DarkKhaki">Abstract:</span></strong></b> <br>
							 Mixed incentives among a population with multiagent teams has been shown to have advantages over a fully cooperative system; however, discovering the best mixture of incentives or team structure is a difficult and dynamic problem.
							 We propose a framework where individual learning agents self-regulate their configuration of incentives through various parts of their reward function.
							 This work extends previous work by giving agents the ability to dynamically update their group alignment during learning and by allowing teammates to have different group alignment.
							 Our model builds on ideas from hierarchical reinforcement learning and meta-learning to learn the configuration of a reward function that supports the development of a behavioral policy.
							 We provide preliminary results in a commonly studied multiagent environment and find that agents can achieve better global outcomes by self-tuning their respective group alignment parameters.
            </p>
						 <!-- <span class="school">Artificial Intelligence for Sports Analytics, IJCAI 2021</span> -->
						 <!-- <a rel="nofollow" href="https://sites.google.com/view/ijcai-aisa-2021/">Artificial Intelligence for Sports Analytics (AISA), at IJCAI 2021</a> -->

					 </div>

           <!-- <p class="mb-4"><b><strong><span style="color:DarkKhaki">Keywords:</span></strong></b> Multiagent Systems, Social Dilemmas, Multiagent Learning </p> -->


					 <p></p>
					 <!-- <h2>ALA Workshop Talk (AAMAS 2022):</h2>
					 <div class="blog-entry-text">
             <iframe width="560" height="315" src="https://www.youtube.com/embed/-RG0LLpYY8o" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
					 </div> -->

					 <div>  <p> </p> </div>

					 <!-- <h2>Preceeding Works:</h2> -->
					 <!-- <h2><a rel="nofollow" href="teams_ijcai22.html">Exploring the Benefits of Teams in Multiagent Learning</a> (IJCAI 2022)</h2> <br> -->
					 <h2>Preceeding Work: <a rel="nofollow" href="credo_lp.html">The Importance of Credo in Multiagent Learning</a> (AAMAS 2023)</h2>

					 <h2>Follow up work: <a rel="nofollow" href="teams_ijcai23.html">Towards a Better Understanding of Learning with Multiagent Teams</a> (IJCAI 2023)</h2>

					 </div>
				 </div>
			 </div>

		 </div>
	 </div>
 </section>


					Copyright &copy; <script>document.write(new Date().getFullYear());</script> All rights reserved | This template is made with <i class="icon-heart text-danger" aria-hidden="true" ></i> by <a href="https://colorlib.com" target="_blank" class="text-primary">Colorlib</a>




	<script src="js/vendor/jquery.min.js"></script>
	<script src="js/vendor/jquery-migrate-3.0.1.min.js"></script>
	<script src="js/vendor/popper.min.js"></script>
	<script src="js/vendor/bootstrap.min.js"></script>

	<script src="js/vendor/jquery.easing.1.3.js"></script>

	<script src="js/vendor/jquery.stellar.min.js"></script>
	<script src="js/vendor/jquery.waypoints.min.js"></script>

	<script src="https://unpkg.com/isotope-layout@3/dist/isotope.pkgd.min.js"></script>
	<script src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
	<script src="js/custom.js"></script>

	<!-- Google Map -->
    <!-- <script src="https://maps.googleapis.com/maps/api/js?key=AIzaSyBVWaKrjvy3MaE7SQ74_uJiULgl1JY0H2s&sensor=false"></script>
    	<script src="js/google-map.js"></script> -->

    </body>
    </html>
